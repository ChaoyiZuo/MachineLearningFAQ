# 机器学习八股文

## Machine Leaning基础概念

1. Overfitting / Underfitting  

    - 过拟合指模型与数据的匹配程度过高，将训练数据一些正常的起伏、波动、异常值也当作是数据的特征，导致模型对新数据的泛化能力变差。具体的表现为在训练集上表现非常优秀，而在验证集/测试集中表现非常差。
    - 解决过拟合的方法一般有：1) 适量减少特征的数量；2) 添加正则项(Regularization)。正则化，顾名思义，目的是为了降低特征对于预测结果的影响能力。常见的正则化项有L1正则项和L2正则项。详见正则化。
    - 欠拟合与过拟合相反，指的是模型缺乏足够的泛化能力。
    - 解决欠拟合的方法有：1) 增加训练轮数；2) 增加模型特征；3) 减少正则项。

2. Bias / Variance trade-off

    偏差(Bias)指模型预测结果与真实值的差异程度，描述了模型的拟合能力；方差(Varience)指模型面对不同数据集时的差异程度，描述了数据扰动对模型的影响。
    一般来说，越简单模型的偏差越高，方差越低；越复杂模型的偏差越低，方差越高。这同样也对应着模型的过拟合与欠拟合。

    权衡偏差与方差的常见方法有交叉认证(Cross-Validation)。K折交叉验证的基本方法为：将训练集平均分为k份，每次训练取其中一份作为验证集，剩下k-1份作为训练集，重复k次，直到每一份小数据集都被作为过验证集。最终的损失为k次训练的损失取平均。

## 正则化 Regularization

1. L1 vs L2

    - L1正则化，又称LASSO，
    - L2正则化，又称Ridge，岭回归。

2. 


